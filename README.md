# reading-papers

**文本大模型**

- [deepseek-llm](./deepseek-llm.md)
- [deepseek-v2技术详解](./deepseek-v2.md)
- [deepseek-v3技术报告](./deepseek-v3技术报告.md)
- [DeepSeek-R1：通过强化学习提升LLM推理能力](./deepseek-r1.md)
- [DeepSeek-R1 解读](./deepseek-r1技术报告.md)

**视觉大模型**

- [deepseek-vl](./deepseek-vl.md)
- [deepseek-vl2](./deepseek-vl2.md)

**function call**

- [openai function call](./openai-fc.md)
- [一文彻底搞懂大模型 - Prompt Engineering、Function Calling、RAG、Fine-tuning](./pe-fc-rag-ft.md)
- [在任意LLM模型中实现function calling](./fc.md)
- [react vs function-call](./react-vs-fc.md)

**prefill-decode 分离**

- [kv cache](./kv-cache.md)
- [pd 分离](./pd.md)
- [Mooncake：基于KVCache的解耦式LLM服务架构](./mooncake.md)

**其他**

- [Agent的九种设计模式](./agent.md)
- [test time scaling](./s1--Simple%20test-time%20scaling.md)
- [A Visual Guide to Mixture of Experts (MoE)](./A%20Visual%20Guide%20to%20Mixture%20of%20Experts%20(MoE).pdf)
- [Training MoEs at Scale with PyTorch](./moe-sacle-with-pytorch.md)
